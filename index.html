<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8"/>
    <title>Local Development Environments Presentation</title>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>
</head>
<body>
<!-- Reveal container -->
<div class="reveal">
    <div class="slides">
        <section>
            <h2>Local Development Environments</h2>
            <h4>Christopher Bartling</h4>

            <aside class="notes">Speaker notes show up with “S”.</aside>
        </section>

        <section>
            <h2>Topics</h2>
            <ul>
                <li>Why use a local development environment?</li>
                <li>What is a local development environment?</li>
                <li>Setting up your own environment</li>
                <li>Best practices and tips</li>
            </ul>
            <aside class="notes">Speaker notes show up with “S”.</aside>
        </section>

        <section>
            <h2>Why use a local development environment?</h2>
            <ul>
                <li>Consistency</li>
                <li>Reproducibility</li>
                <li>Isolation</li>
                <li>Efficiency</li>
                <li>Safe experimentation</li>
                <li>Parity with QA and production</li>
                <li>Quick feedback</li>
                <li>Improved productivity</li>
            </ul>
            <aside class="notes">
                Local development environments powered by Docker Compose are valuable because they provide
                consistency, reproducibility, and isolation across machines and stages of development. By containerizing
                applications and their dependencies, developers can quickly spin up complex, multi-service stacks that
                closely mirror QA and production. This makes onboarding new developers faster, enables safe
                experimentation, and reduces the risk of environment-related bugs.

                They also help teams maintain parity with production systems, which are often container-orchestrated in
                Kubernetes or similar platforms. This alignment means issues are caught earlier in development, CI/CD
                pipelines run more reliably, and scaling or networking scenarios can be tested locally. In short,
                Docker Compose creates efficient, production-like environments that improve collaboration,
                debugging, and software quality.

                Local development environments with Docker Compose shorten feedback loops because they let
                developers test code changes against a realistic, production-like setup immediately on their machine.
                Instead of waiting for builds to deploy to a shared integration environment, developers can run the full
                stack—including databases, message brokers, and supporting services—locally with a single command. This
                means issues like misconfigurations, dependency mismatches, or integration bugs are caught early, often
                within minutes of writing code.

                By reducing reliance on remote environments during development, these setups also cut down on delays
                caused by resource contention or slow deployment pipelines. The result is faster iteration, quicker
                validation of changes, and a smoother path from development to production. In essence, local Docker
                Compose environments give developers instant, reliable feedback, which drives productivity and improves
                software quality.
            </aside>
        </section>

        <section>
            <h2>What is a local development environment?</h2>
            <ul>
                <li>Docker Compose running locally</li>
                <li>Containers for service dependencies</li>
                <li>Mirrors the production environment</li>
                <li>Ephemeral</li>
                <li>Experimentation sandbox</li>
            </ul>
            <aside class="notes">
                A local development environment using Docker Compose is a setup where developers run the required
                services (like databases, caches, message brokers, or APIs) inside containers on their own machine.
                Instead of manually installing and configuring these dependencies on the local system,
                developers define them in a Docker Compose YAML file and start the entire stack with a single command.
                This creates a consistent, reproducible environment that mirrors how the application will run in
                production.

                With this approach, developers can work in isolation without interfering with each other, quickly
                spinning up or tearing down complete environments, and test changes against realistic infrastructure.
                Essentially, it provides a production-like sandbox on a local development system, enabling faster
                debugging, safer experimentation, and smoother collaboration across a team.

                The local development environment is ephemeral, meaning the setup can be created, destroyed, and
                recreated at will without manual effort or long-term dependencies. This is important because it ensures
                developers always have a clean, consistent starting point, free from leftover configuration, corrupted
                data, or version mismatches that can creep in over time. By treating environments as disposable, teams
                reduce “it works on my machine” issues and avoid wasting time debugging environment drift.

                It also encourages safe experimentation—developers can try risky changes, test migrations, or simulate
                failures knowing they can reset everything back to a known good state instantly. This disposability
                aligns local development with modern DevOps practices, making environments reliable, reproducible, and
                easy to share across the team.
            </aside>
        </section>

        <section>
            <h2>Setting up your own environment</h2>
            <ul>
                <li>Docker and Docker Compose</li>
                <li>Service images</li>
            </ul>
            <aside class="notes">
                Docker Compose is a tool that lets developers define and run multi-container applications using a single
                YAML configuration file. Instead of starting each service manually, developers can describe the entire
                stack—application, database, cache, message broker, etc.—and launch everything with a single command
                (docker compose up).

                Docker Compose is especially useful for local development because it provides a consistent, reproducible
                environment that mirrors production while staying lightweight and easy to manage. Developers can spin up
                or tear down complex setups quickly.

                Packaging infrastructure services like MS SQL Server, Kafka, and MongoDB as Open Container Initiative or
                OCI images makes them
                first-class, versioned build artifacts you can pull and run the same way you do your app containers.
                Each service publishes an image (often “official” or vendor-maintained) with sane defaults, ports
                exposed, and knobs for configuration through environment variables. In Docker Compose, you declare these
                services with images, map ports for local access, attach persistent volumes for data, and pin versions.
                The result is a reproducible, disposable environment that developers can spin up with one command and
                tear down without polluting their machines.

                Because these services are OCI images, teams can lock exact versions, switch variants (ARM vs x86) on
                Apple Silicon, and use Compose profiles to include/exclude heavier dependencies as needed. Data
                durability and reset behavior are controlled with volumes: mount named volumes for day-to-day work; drop
                them for clean, ephemeral test runs.
            </aside>
        </section>

        <section>
            <h2>Databases</h2>
            <ul>
                <li>Microsoft SQL Server</li>
                <li>MongoDB</li>
                <li>Database initialization and seeding</li>
            </ul>
            <aside class="notes">
                With Docker Compose, you can run databases like MS SQL Server and MongoDB as services alongside your app
                so everything starts with one command and shares a private network. Each DB gets its own container,
                persistent volume (so data survives restarts), and environment variables for credentials.

                Initialization and seeding are handled slightly differently per database.

                For MS SQL Server, the official image doesn’t auto-run scripts by default; common practice is to add a
                small “init” one-shot container that waits for SQL Server to become healthy and then executes your .sql
                files via sqlcmd (or bake that logic into a custom entrypoint).

                For MongoDB, the official image automatically runs any .js or .sh files placed in
                /docker-entrypoint-initdb.d on the first launch of a fresh data volume. You can use this to create
                users, databases, and seed collections (including running mongorestore from a dump).

                In both cases, Compose healthchecks ensure your app starts only after the database is ready, and
                volumes keep data persistent while still allowing you to tear everything down and recreate a clean
                environment when you need to reseed.
            </aside>
        </section>

        <section>
            <h2>Kafka and Schema Registry</h2>
            <ul>
                <li>Confluent images</li>
                <li>Kafka UI</li>
                <li>Schema Registry UI</li>
            </ul>
            <aside class="notes">
                With Docker Compose, you can run a single-node Kafka broker (in KRaft mode) and Confluent Schema
                Registry as services on the same private network as your app. The Kafka container exposes
                standard ports and persists data to a volume; Schema Registry points at the Kafka bootstrap servers and
                stores schemas in Kafka’s internal _schemas topic. Your application
                then connects using the broker’s address and the Schema Registry URL (e.g.,
                SCHEMA_REGISTRY_URL=http://schema-registry:8081) so producers/consumers can serialize/deserialize events
                with Avro/JSON Schema/Protobuf.

                Topic initialization is typically handled by a small, one-shot “init” service that waits for Kafka’s
                healthcheck and then runs kafka-topics.sh to create topics with desired partitions/replication and
                configs, or uses kcat/Confluent CLI. This keeps local setups reproducible—docker compose up yields the
                same topics every time.

                Schema registration can be automated similarly with a a small, one-shot “init”
                service to register Avro schemas. Pre-registering via an init container makes local CI-like runs
                deterministic and lets you catch incompatible changes early.

                In short, Compose turns Kafka + Schema Registry into a turnkey, production-like messaging stack on
                your laptop: services boot in order (depends_on + healthchecks), topics and schemas are created
                predictably, and your app immediately has reliable messaging with strong contracts—speeding up local
                integration testing and shortening feedback loops.

                The Kafka UI service is important in a local dev environment because it provides a simple, visual way
                to inspect and manage Kafka without relying only on CLI tools. With Kafka UI, developers can browse
                topics,
                partitions, and consumer groups, check offsets and lag, and even produce or consume test messages
                directly from the browser. This makes it much easier to debug integration issues, verify that services
                are publishing/consuming correctly, and explore message payloads during development.

                The Schema Registry UI service is important in a local Docker Compose environment because it gives
                developers an
                easy way to explore, register, and manage schemas without relying solely on API calls or scripts.
                Through the UI, you can quickly see which subjects exist, inspect schema versions, check compatibility
                settings, and validate whether producers and consumers are aligned. This visibility makes it much easier
                to debug serialization issues, test schema evolution, and ensure contracts between services are being
                respected.
            </aside>
        </section>

        <section>
            <h2>WireMock</h2>
            <ul>
                <li>API mocking</li>
                <li>Initialization of routes and payloads</li>
            </ul>
            <aside class="notes">
                WireMock can be run as a containerized service on the same network as your
                app to provide fast, isolated API mocks. Your app calls http://wiremock:8080 (or whatever service
                name/port you set), and WireMock serves predefined stubs so you can develop and test without reaching
                real third-party APIs. You typically mount two volumes: mappings/ for stub definitions and __files/ for
                sample payloads. This keeps mocks reproducible across the team: docker compose up reliably brings up the
                same mocked endpoints, enables end-to-end flows locally, and shortens feedback loops.

                Initialization of API URIs (i.e., seeding WireMock with routes) can be done in two ways. The simplest is
                file-based seeding: place JSON/YAML stub files in mappings/ that declare the request matchers and
                responses (status, headers, body or bodyFileName). On first start, WireMock automatically loads these so
                endpoints like /oauth/token, /orders/*, or /health are ready immediately.

                Alternatively, you can use an init container that waits for WireMock’s health and then calls the Admin
                API (e.g., POST /__admin/mappings) to register stubs dynamically, set global settings (delays/faults),
                or import recordings. This approach is great when you need environment-specific values, templating, or
                to toggle behaviors (proxying, latency injection) per run.

                Together, Docker Compose and WireMock give you a
                production-like, controllable API surface for local development use—no external API dependencies
                required.
            </aside>
        </section>

        <section>
            <h2>Best practices and tips</h2>
            <ul>
                <li>Initialization containers</li>
                <li>Container health checks</li>
                <li>Remove volumes</li>
                <li>Remove orphans</li>
            </ul>
            <aside class="notes">
                In a Docker Compose setup, initialization containers are lightweight, short-lived services that run
                before your main application services to prepare the environment. For example, a database init container
                might wait for MS SQL Server or PostgreSQL to become healthy, then execute SQL scripts to create
                schemas, tables, and seed data. Similarly, a Kafka init container could run kafka-topics.sh or use kcat
                to create required topics, partitions, and configurations. These init containers typically use
                depends_on with healthchecks to ensure they run only after the target service is ready, and then exit
                cleanly once initialization is complete.

                This pattern helps keep your Compose environment reproducible and self-contained: docker compose up
                automatically brings up not only the core services but also the data structures, topics, or
                configuration they require. Developers get a consistent, production-like environment every time without
                manual setup, which speeds up onboarding and ensures integration tests run reliably.

                Service health checks in Docker Compose are important because they verify that a container is not just
                running but actually ready to serve requests. For example, a database container may start quickly, but
                the database engine might still be initializing; without a health check, dependent services could fail
                to connect. By defining health checks, Compose can delay startup of other services until the target is
                truly ready, reducing race conditions and flaky errors during development.

                This improves the reliability and reproducibility of local environments: every time you run docker
                compose up, your application stack comes online in the correct order and with dependencies in a usable
                state. Health checks also make debugging easier—Compose will surface whether a service is unhealthy,
                helping developers quickly identify where failures are happening.

                Removing volumes in ephemeral Docker Compose environments is important because it ensures you start with
                a clean, consistent state every time. Persistent volumes hold databases, message logs, or cached files;
                if left behind, they can cause environment drift where stale data, old schemas, or misconfigured topics
                linger across runs. This often leads to confusing “it worked yesterday” issues that waste time
                debugging.

                By removing volumes when tearing down your environment, you align with the principle of ephemerality:
                environments should be disposable and reproducible on demand. This makes it easy to reseed databases,
                recreate Kafka topics, or reload test fixtures consistently. It also encourages safer experimentation,
                since developers know they can reset everything with a single command and avoid being blocked by hidden
                state.

                Removing orphan containers in Docker Compose is important because orphans are leftover services from
                previous Compose runs that are no longer defined in your current configuration. If they aren’t removed,
                they can interfere with networking, ports, or data flow, leading to unexpected behavior where your
                application appears broken even though the configuration is correct. For example, an old version of a
                database or proxy might still be running and conflicting with the new stack.

                In an ephemeral local development environment, the goal is consistency and reproducibility. Removing
                orphans ensures that only the services defined in your current docker-compose.yml are active, keeping
                the environment clean and predictable. This reduces debugging time, eliminates conflicts, and reinforces
                the disposable nature of local setups—helping developers spin up fresh, reliable environments every
                time.
            </aside>
        </section>

    </div>
</div>

<!-- App entry -->
<script type="module" src="/src/main.js"></script>
</body>
</html>
